{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e3c1a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs336_basics.transformer import Transformer\n",
    "from cs336_basics.train import AdamW, get_batch, gradient_clipping, get_lr_schedule,CrossEntropyLossWithLogits, load_checkpoint, save_checkpoint\n",
    "from config import Config\n",
    "import tiktoken\n",
    "from torch import nn\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "cfg = Config()\n",
    "model = Transformer(\n",
    "        cfg.d_model, cfg.num_heads, cfg.d_ff, cfg.context_length, cfg.rope_theta, cfg.vocab_size, cfg.num_layers\n",
    "    ).to(cfg.device)\n",
    "load_checkpoint(Path(cfg.ckpt_path) / \"dev_0099.pt\", model, optimizer=None)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6e51a107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a little boy named Ben. Ben loved to explore the woods. The cat was very happy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def decode(model: nn.Module, input_ids: torch.Tensor, max_new_tokens: int, temperature: float, p: float) -> torch.Tensor:\n",
    "    model.eval()\n",
    "    token_generated = 0\n",
    "    while token_generated < max_new_tokens:\n",
    "        logits = model(input_ids)[:, -1, :]\n",
    "        logits = logits / temperature  \n",
    "        probs = torch.softmax(logits, dim = 1)          \n",
    "        if 0.0 < p < 1.0:\n",
    "            sorted, indices = torch.sort(probs, descending=True)\n",
    "            cumsum = torch.cumsum(sorted, dim=1)\n",
    "            trimmed = cumsum > p\n",
    "            trimmed[: , 0] = False\n",
    "            sorted[trimmed] = 0\n",
    "            next_token_id = torch.multinomial(sorted, num_samples=1)\n",
    "            next_token = indices.gather(1, next_token_id)\n",
    "        else:\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "        if next_token.item() == 50256:\n",
    "            break\n",
    "        input_ids = torch.cat((input_ids, next_token), dim=1)\n",
    "        token_generated += 1\n",
    "    return input_ids\n",
    "prompt = \"Once upon a time there was a little boy named Ben. Ben loved to explore\"\n",
    "input_ids = tokenizer.encode(prompt)\n",
    "input_ids = torch.as_tensor(input_ids, dtype=torch.int64).unsqueeze(0)\n",
    "output = decode(model, input_ids, max_new_tokens=100, temperature=0.5, p = 0.9).squeeze().tolist()\n",
    "print(tokenizer.decode(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150ba07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d2d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-basics (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
